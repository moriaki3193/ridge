# Cross Validation
精度100%とか学習の結果としてありえない。
モデルの汎化性能を保証する方法が必要になる。

> 次数を上げた（説明変数を増やした）ことで学習データのシグナルだけではなくノイズにまでフィットしてしまった

モデルの汎化性能を評価する方法が交差検証。
様々なやり方がある。
勘違いしてはいけないのは、交差検証そのものが、一つの手法というわけではないということ。

## 一覧
| Method | Description | Usecase |
|:-------|:------------|:--------|
| hold-out | ランダムに2つに学習データを振り分けて、片方で学習、もう片方で精度を評価 | データが十分に大きい |
| k-folds | 学習データをk個に分割して、k-1個で学習、残りの1個で精度を評価することをk回繰り返す | 一般的 |
| Leave-One-Out | 学習データのうちサンプルを1つ抜いて学習させて、残った1サンプルへのモデルの予測値を比較するのをサンプルサイズ分繰り返す | データが小規模であり、学習データの数をできるだけ減らしたくない場合 |
| bootstrap | |
| Out-Of-Bag | |

## 正則化
説明変数の数を大きくすれば、モデルが過学習を起こしやすいことはこれまでに説明した通り。
学習の段階で過学習を防ぐための手法の一つに正則化がある。

## leakage
説明変数にエンティティのIDといったものを含める場合に注意が必要。
データセットの中に、そのIDについてのインスタンスが1件しか存在しない、といったケースでは、IDについての説明変数が、その1件に無理に合わせるように学習されるため、簡単に過学習する。

> 本文を読んで字の如しで、本来は「テストデータの中にあるべき変数が学習（訓練）データに洩れて(leak)しまっていること」という意味

## まとめ
- あまりにも精度が高いケースでは、必ずといっていいほどモデルがおかしい。
- 交差検証は基本中の基本。簡単な手法でも良いから必ず行うこと。
- IDといった変数はleakageに陥りがち。繰り返しの有無を事前に必ず確認すること。